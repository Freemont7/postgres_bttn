{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texas Census to BTTN Conflation\n",
    "\n",
    "This example notebook demonstrates the use of Jupyter Notebook, PostgreSQL + PostGIS, and Python to spatially join census data to Texas Department of Transportation's Bicycle Tourism Trails (BTT) Example Network.\n",
    "\n",
    "## Project Goal\n",
    "\n",
    "Determine the income distribution of households living within 5 km of TxDOT's Bicycle Tourism Trail Network (BTTN).\n",
    "\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "* Bicycle Tourism Trails (BTT) Example Network Shapefile (EPSG:3857)\n",
    "* ACS 5-Year Estimates 2012 – 2017 Table B19001 \"HOUSEHOLD INCOME IN THE PAST 12 MONTHS IN 2017 INFLATION-ADJUSTED DOLLARS\" (EPSG:4326)\n",
    "* ACS 2017 TIGER/Line Shapefile - Block Groups (EPSG:4269)\n",
    "\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Load the BTTN and Census Shapefiles\n",
    "2. Load the Census ACS data with household income\n",
    "3. Create a 5 km buffer around the BTTN\n",
    "4. Measure the overlapping portion between each Census Block Group shape and the BTTN buffer\n",
    "5. Join the apportioned Census household income data to the BTTN buffer\n",
    "6. Visualize the results\n",
    "\n",
    "## Pre-reqs\n",
    "\n",
    "* PostgreSQL with PostGIS extension installed\n",
    "* Python 3\n",
    "* SQL Extension for Jupyter Notebook\n",
    "\n",
    "## A Note on Spatial Projections\n",
    "\n",
    "Length and area spatial calculations cannot (easily) be done using a lat/long projection (e.g. Web Mercator). For the purposes of our work below, we'll reproject each shapefile as we load it into a common ** WGS 84 / UTM Zone 13N ** projection (EPSG:32613) which measures all coordinates in _meters_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import io\n",
    "\n",
    "# PostgreSQL Connection String\n",
    "DSN = \"dbname=bttn user=postgres\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the database and enable the PostGIS extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!createdb bttn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!psql -c \"CREATE EXTENSION postgis;\" bttn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the SQL Extension for Jupyter Notebook and Connect\n",
    "\n",
    "\\* Note: if you do not have the SQL Extension installed, simply replace the \\%\\%sql cells  with a shell command: `psql -c \"SQL QUERY\" bttn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "postgresql://postgres:@localhost/bttn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Bicycle Tourism Trails Network Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shp2pgsql -s 3857:32613 -dI \"shp/bttn/btt.shp\" bttn | psql -d bttn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Census Data\n",
    "\n",
    "### Load the 2017 TIGER/Line Census Block Group Shapefile (Texas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shp2pgsql -s 4269:32613 -dI \"shp/tl_2017_48_bg/tl_2017_48_bg.shp\" tl_2017_48_bg | psql -d bttn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ACS 2012 - 2017 Household Income Tabular Data\n",
    "\n",
    "First, create the destination table. Then, copy in the tabular data. This can be done directly with SQL (a full path is required—a relative path can be used if known relative to PostgreSQL's binaries). Alternatively, this can be done using Python with `psycopg2.cursor().copy_from()`, e.g. (not run):\n",
    "\n",
    "```\n",
    "conn = psycopg2.connect(DSN)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE acs_income (\n",
    "    geoid TEXT,\n",
    "    households_total INTEGER,\n",
    "    households_0_10k INTEGER,\n",
    "    households_10_15k INTEGER,\n",
    "    households_15_20k INTEGER,\n",
    "    households_20_25k INTEGER,\n",
    "    households_25_30k INTEGER,\n",
    "    households_30_35k INTEGER,\n",
    "    households_35_40k INTEGER,\n",
    "    households_40_45k INTEGER,\n",
    "    households_45_50k INTEGER,\n",
    "    households_50_60k INTEGER,\n",
    "    households_60_75k INTEGER,\n",
    "    households_75_100k INTEGER,\n",
    "    households_100_125k INTEGER,\n",
    "    households_125_150k INTEGER,\n",
    "    households_150_200k INTEGER,\n",
    "    households_200k_plus INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "f = open('data/ACS_17_5YR_B19001.csv, 'r')\n",
    "f.readline() # skip the header line\n",
    "cur.copy_from(f, 'acs_income', sep=',', null='')\n",
    "\n",
    "conn.commit()\n",
    "            \n",
    "cur.close()\n",
    "conn.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE acs_income (\n",
    "    geoid TEXT,\n",
    "    households_total INTEGER,\n",
    "    households_0_10k INTEGER,\n",
    "    households_10_15k INTEGER,\n",
    "    households_15_20k INTEGER,\n",
    "    households_20_25k INTEGER,\n",
    "    households_25_30k INTEGER,\n",
    "    households_30_35k INTEGER,\n",
    "    households_35_40k INTEGER,\n",
    "    households_40_45k INTEGER,\n",
    "    households_45_50k INTEGER,\n",
    "    households_50_60k INTEGER,\n",
    "    households_60_75k INTEGER,\n",
    "    households_75_100k INTEGER,\n",
    "    households_100_125k INTEGER,\n",
    "    households_125_150k INTEGER,\n",
    "    households_150_200k INTEGER,\n",
    "    households_200k_plus INTEGER\n",
    ");\n",
    "\n",
    "COPY acs_income (\n",
    "    geoid, households_total, households_0_10k, households_10_15k, households_15_20k, \n",
    "    households_20_25k, households_25_30k, households_30_35k, households_35_40k, \n",
    "    households_40_45k, households_45_50k, households_50_60k, households_60_75k, \n",
    "    households_75_100k, households_100_125k, households_125_150k, households_150_200k, \n",
    "    households_200k_plus\n",
    ")\n",
    "FROM '/Users/markegge/projects/postgres_bttn/data/ACS_17_5YR_B19001.csv' -- requires a full path\n",
    "WITH CSV HEADER;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffer the BTTN Shape\n",
    "\n",
    "Buffer by 5000 m. Create a spatial index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS bttn_buffered CASCADE;\n",
    "\n",
    "CREATE TABLE bttn_buffered AS\n",
    "SELECT\n",
    "    gid, objectid, type, miles, existing_f, \n",
    "    future_fac, status_, prelim_rte,\n",
    "    ST_Buffer(geom, 5000) AS geom\n",
    "FROM bttn;\n",
    "\n",
    "CREATE INDEX btt_geom_idx ON bttn_buffered USING GIST (geom);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the overlap between Census Block Groups and BTTN Segments\n",
    "\n",
    "First, determine the percent overlap between each Census Block Group shape and each BTTN buffer shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS overlap;\n",
    "\n",
    "CREATE TABLE overlap AS (\n",
    "    SELECT \n",
    "        btt.gid AS btt_gid,\n",
    "        btt.objectid AS btt_objectid, \n",
    "        ST_Area(btt.geom) AS btt_area,\n",
    "        bg.geoid AS acs_geoid,\n",
    "        ST_Area(bg.geom) AS acs_area,\n",
    "        ST_Area(ST_Intersection(btt.geom, bg.geom)) AS overlap_area,\n",
    "        households.*\n",
    "    FROM bttn_buffered btt\n",
    "    JOIN tl_2017_48_bg bg ON ST_Intersects(btt.geom, bg.geom)\n",
    "    INNER JOIN acs_income households USING (geoid)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE overlap ADD COLUMN overlap_pct NUMERIC;\n",
    "\n",
    "UPDATE overlap SET overlap_pct = overlap_area / acs_area;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT SUM(households_total) FROM overlap;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "UPDATE overlap SET\n",
    "households_total = (households_total * overlap_pct)::INTEGER,\n",
    "households_0_10k = (households_0_10k * overlap_pct)::INTEGER,\n",
    "households_10_15k = (households_10_15k * overlap_pct)::INTEGER,\n",
    "households_15_20k = (households_15_20k * overlap_pct)::INTEGER,\n",
    "households_20_25k = (households_20_25k * overlap_pct)::INTEGER,\n",
    "households_25_30k = (households_25_30k * overlap_pct)::INTEGER,\n",
    "households_30_35k = (households_30_35k * overlap_pct)::INTEGER,\n",
    "households_35_40k = (households_35_40k * overlap_pct)::INTEGER,\n",
    "households_40_45k = (households_40_45k * overlap_pct)::INTEGER,\n",
    "households_45_50k = (households_45_50k * overlap_pct)::INTEGER,\n",
    "households_50_60k = (households_50_60k * overlap_pct)::INTEGER,\n",
    "households_60_75k = (households_60_75k * overlap_pct)::INTEGER,\n",
    "households_75_100k = (households_75_100k * overlap_pct)::INTEGER,\n",
    "households_100_125k = (households_100_125k * overlap_pct)::INTEGER,\n",
    "households_125_150k = (households_125_150k * overlap_pct)::INTEGER,\n",
    "households_150_200k = (households_150_200k * overlap_pct)::INTEGER;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT SUM(households_total) FROM overlap;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using Pandas, let's grab out the data from the database and transform it into something we can display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with psycopg2.connect(DSN) as conn:\n",
    "    df = pd.read_sql_query(\"SELECT * FROM overlap;\", conn)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt our data\n",
    "mlt = pd.melt(df, \n",
    "        id_vars=['geoid'], \n",
    "        value_vars=['households_0_10k', 'households_10_15k', 'households_15_20k', \n",
    "                    'households_20_25k', 'households_25_30k', 'households_30_35k', \n",
    "                    'households_35_40k', 'households_40_45k', 'households_45_50k', \n",
    "                    'households_50_60k', 'households_60_75k', 'households_75_100k', \n",
    "                    'households_100_125k', 'households_125_150k', 'households_150_200k', \n",
    "                    'households_200k_plus'],\n",
    "             var_name='group',\n",
    "             value_name='households')\n",
    "\n",
    "mlt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = mlt.groupby('group', as_index=False)[['households']].sum()\n",
    "grouped['group_lower'] = grouped['group'].str.extract(r'_(.+?)k?_', expand=False)\n",
    "grouped['group_lower'] = pd.to_numeric(grouped.group_lower)\n",
    "grouped.sort_values('group_lower', inplace=True)\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y_pos = np.arange(len(grouped))\n",
    "plt.bar(y_pos, grouped['households'], alpha=0.5)\n",
    "plt.xticks(y_pos, grouped['group'], rotation=90)\n",
    "plt.title('Households within 5kn of BTTN by Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
